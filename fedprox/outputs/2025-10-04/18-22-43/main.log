[2025-10-04 18:22:54,654][flwr][DEBUG] - Pre-registering run with id 2351710355451443514
[2025-10-04 18:22:54,656][flwr][DEBUG] - Using InMemoryState
[2025-10-04 18:22:54,656][flwr][DEBUG] - Using InMemoryState
[2025-10-04 18:22:54,660][flwr][DEBUG] - Using InMemoryState
[2025-10-04 18:22:54,660][flwr][DEBUG] - Registered 3 nodes
[2025-10-04 18:22:54,661][flwr][DEBUG] - Supported backends: ['ray']
[2025-10-04 18:22:54,672][flwr][DEBUG] - Initialising: RayBackend
[2025-10-04 18:22:54,673][flwr][DEBUG] - Backend config: {'num_cpus': 2, 'num_gpus': 0.0, 'init_args': {'logging_level': 30, 'log_to_driver': True}, 'client_resources': {'num_cpus': 2, 'num_gpus': 0}, 'actor': {'tensorflow': 0}}
[2025-10-04 18:22:55,392][flwr][INFO] - Starting Flower ServerApp, config: num_rounds=3, no round_timeout
[2025-10-04 18:22:55,393][flwr][INFO] - 
[2025-10-04 18:22:55,394][flwr][INFO] - [INIT]
[2025-10-04 18:22:55,394][flwr][INFO] - Requesting initial parameters from one random client
[2025-10-04 18:23:14,931][flwr][DEBUG] - Constructed ActorPool with: 1 actors
[2025-10-04 18:23:14,932][flwr][DEBUG] - Using InMemoryState
[2025-10-04 18:23:35,311][flwr][ERROR] - An exception was raised when processing a message by RayBackend
[2025-10-04 18:23:35,311][flwr][ERROR] - [36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 144, in __call__
    return self._call(message, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 128, in ffn
    out_message = handle_legacy_message_from_msgtype(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/message_handler/message_handler.py", line 96, in handle_legacy_message_from_msgtype
    client = client_fn(context)
             ^^^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 424, in client_fn
    numpy_client =  FederatedClient(
                    ^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 65, in __init__
    self.net.to(self.net)
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1328, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)


The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
[2025-10-04 18:23:35,320][flwr][ERROR] - Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py", line 111, in worker
    out_mssg, updated_context = backend.process_message(message, context)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py", line 189, in process_message
    raise ex
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py", line 176, in process_message
    ) = self.pool.fetch_result_and_return_actor_to_pool(future)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/ray_transport/ray_actor.py", line 480, in fetch_result_and_return_actor_to_pool
    _, out_mssg, updated_context = ray.get(future)
                                   ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 2639, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py", line 864, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ClientAppException): [36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 144, in __call__
    return self._call(message, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 128, in ffn
    out_message = handle_legacy_message_from_msgtype(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/message_handler/message_handler.py", line 96, in handle_legacy_message_from_msgtype
    client = client_fn(context)
             ^^^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 424, in client_fn
    numpy_client =  FederatedClient(
                    ^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 65, in __init__
    self.net.to(self.net)
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1328, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)


The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)

[2025-10-04 18:23:35,346][flwr][ERROR] - ServerApp thread raised an exception: Message contains an Error (reason: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 144, in __call__
    return self._call(message, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 128, in ffn
    out_message = handle_legacy_message_from_msgtype(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/message_handler/message_handler.py", line 96, in handle_legacy_message_from_msgtype
    client = client_fn(context)
             ^^^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 424, in client_fn
    numpy_client =  FederatedClient(
                    ^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 65, in __init__
    self.net.to(self.net)
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1328, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)


The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)'>). It originated during client-side execution of a message.
[2025-10-04 18:23:35,352][flwr][ERROR] - Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/run_simulation.py", line 283, in server_th_with_start_checks
    updated_context = _run(
                      ^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/run_serverapp.py", line 62, in run
    server_app(grid=grid, context=context)
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/server_app.py", line 166, in __call__
    start_grid(
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/compat/app.py", line 90, in start_grid
    hist = run_fl(
           ^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/server.py", line 492, in run_fl
    hist, elapsed_time = server.fit(
                         ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/server.py", line 93, in fit
    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/server.py", line 284, in _get_initial_parameters
    get_parameters_res = random_client.get_parameters(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/compat/grid_client_proxy.py", line 63, in get_parameters
    in_recorddict = self._send_receive_recorddict(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/server/compat/grid_client_proxy.py", line 131, in _send_receive_recorddict
    raise ValueError(
ValueError: Message contains an Error (reason: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 144, in __call__
    return self._call(message, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/client_app.py", line 128, in ffn
    out_message = handle_legacy_message_from_msgtype(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/client/message_handler/message_handler.py", line 96, in handle_legacy_message_from_msgtype
    client = client_fn(context)
             ^^^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 424, in client_fn
    numpy_client =  FederatedClient(
                    ^^^^^^^^^^^^^^^^
  File "/content/cluster-CDCSF/fedprox/fedprox/client.py", line 65, in __init__
    self.net.to(self.net)
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1328, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)


The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=12655, ip=172.28.0.12, actor_id=c83bed43d91f78d189b707ae01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7a96ac3cf230>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/flwr/simulation/ray_transport/ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: to() received an invalid combination of arguments - got (ModelCDCSF), but expected one of:
 * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)
 * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)'>). It originated during client-side execution of a message.

[2025-10-04 18:23:35,437][flwr][DEBUG] - ServerApp finished running.
[2025-10-04 18:23:35,437][flwr][DEBUG] - Triggered stop event for Simulation Engine.
[2025-10-04 18:23:36,337][flwr][DEBUG] - Terminated 1 actors
[2025-10-04 18:23:38,018][flwr][DEBUG] - Terminated RayBackend
[2025-10-04 18:23:41,021][flwr][DEBUG] - Queue timeout. No context received.
